{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 247,
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "look_back = 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "def create_klines_dataset(data) :\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "\n",
    "    for i in range(look_back, len(data)):\n",
    "        X_train.append(data[i-look_back:i, 0:9])\n",
    "        y_train.append(data[i, 3])\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], look_back, 9))\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# klines_dataset = pd.read_csv('resource/dataset/binance/klines-BTCUSDT-1m_20220101090000_20220101205900.csv')\n",
    "klines_dataset = pd.read_csv('resource/dataset/binance/klines-BTCUSDT-1m_20220101210000_20220102085900.csv')\n",
    "del klines_dataset['openTime']\n",
    "del klines_dataset['closeTime']\n",
    "del klines_dataset['ignore']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "klines_dataset_scaled = scaler.fit_transform(klines_dataset)\n",
    "# klines_dataset\n",
    "# klines_dataset_scaled.shape\n",
    "x_train,y_train = create_klines_dataset(klines_dataset_scaled)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "outputs": [
    {
     "data": {
      "text/plain": "0.008537321072736859"
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "outputs": [
    {
     "data": {
      "text/plain": "(720, 9)"
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "def create_klines_dataset(data) :\n",
    "    y = np.array(data[4])\n",
    "    del data['openTime']\n",
    "    del data['closeTime']\n",
    "    # del data['ignore']\n",
    "    x = np.array(data)\n",
    "\n",
    "    x = np.reshape(x, (x.shape[0],  look_back, 1))\n",
    "    y = np.reshape(y, (y.shape[0],  look_back, 1))\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=1)\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=1)\n",
    "\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# klines_dataset = pd.read_csv('resource/dataset/binance/klines-BTCUSDT-1m_20220101090000_20220101205900.csv')\n",
    "klines_dataset = pd.read_csv('resource/dataset/binance/klines-BTCUSDT-1m_20220101210000_20220102085900.csv')\n",
    "del klines_dataset['openTime']\n",
    "del klines_dataset['closeTime']\n",
    "del klines_dataset['ignore']\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "klines_dataset.shape\n",
    "# klines_dataset_scaled = scaler.fit_transform(klines_dataset)\n",
    "# # klines_dataset_scaled.shape\n",
    "# x_train, x_val, x_test, y_train, y_val, y_test = create_klines_dataset(klines_dataset_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [
    {
     "data": {
      "text/plain": "         open      high       low     close    volume  quoteAssetVolume  \\\n0    46758.87  46826.83  46756.30  46825.01   7.61286      3.562220e+05   \n1    46825.01  46825.02  46800.49  46807.99   7.62883      3.570913e+05   \n2    46805.14  46814.42  46761.76  46808.04  33.52525      1.568461e+06   \n3    46808.04  46815.26  46792.36  46793.94   4.82469      2.258093e+05   \n4    46793.94  46826.00  46793.94  46798.81   5.88667      2.755360e+05   \n..        ...       ...       ...       ...       ...               ...   \n715  47687.26  47778.48  47607.26  47734.33  87.40123      4.168367e+06   \n716  47728.96  47748.81  47699.54  47739.99  19.58113      9.343993e+05   \n717  47740.00  47799.88  47711.43  47771.53  32.42206      1.548339e+06   \n718  47771.52  47771.53  47720.25  47722.99  20.97965      1.001710e+06   \n719  47722.98  47741.23  47700.00  47722.65  18.76054      8.953514e+05   \n\n     numberOfTrades  takerBuyBaseAssetVolume  takerBuyQuoteAssetVolume  \n0               501                  3.79922              1.777819e+05  \n1               381                  2.99694              1.402743e+05  \n2               781                 18.85000              8.817704e+05  \n3               437                  0.92098              4.310377e+04  \n4               430                  3.03827              1.422078e+05  \n..              ...                      ...                       ...  \n715            1359                 46.90157              2.237324e+06  \n716             650                  7.49365              3.576146e+05  \n717             904                 15.75298              7.522625e+05  \n718             618                  5.00430              2.389313e+05  \n719             633                 12.42697              5.930911e+05  \n\n[720 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>quoteAssetVolume</th>\n      <th>numberOfTrades</th>\n      <th>takerBuyBaseAssetVolume</th>\n      <th>takerBuyQuoteAssetVolume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>46758.87</td>\n      <td>46826.83</td>\n      <td>46756.30</td>\n      <td>46825.01</td>\n      <td>7.61286</td>\n      <td>3.562220e+05</td>\n      <td>501</td>\n      <td>3.79922</td>\n      <td>1.777819e+05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>46825.01</td>\n      <td>46825.02</td>\n      <td>46800.49</td>\n      <td>46807.99</td>\n      <td>7.62883</td>\n      <td>3.570913e+05</td>\n      <td>381</td>\n      <td>2.99694</td>\n      <td>1.402743e+05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>46805.14</td>\n      <td>46814.42</td>\n      <td>46761.76</td>\n      <td>46808.04</td>\n      <td>33.52525</td>\n      <td>1.568461e+06</td>\n      <td>781</td>\n      <td>18.85000</td>\n      <td>8.817704e+05</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>46808.04</td>\n      <td>46815.26</td>\n      <td>46792.36</td>\n      <td>46793.94</td>\n      <td>4.82469</td>\n      <td>2.258093e+05</td>\n      <td>437</td>\n      <td>0.92098</td>\n      <td>4.310377e+04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>46793.94</td>\n      <td>46826.00</td>\n      <td>46793.94</td>\n      <td>46798.81</td>\n      <td>5.88667</td>\n      <td>2.755360e+05</td>\n      <td>430</td>\n      <td>3.03827</td>\n      <td>1.422078e+05</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>715</th>\n      <td>47687.26</td>\n      <td>47778.48</td>\n      <td>47607.26</td>\n      <td>47734.33</td>\n      <td>87.40123</td>\n      <td>4.168367e+06</td>\n      <td>1359</td>\n      <td>46.90157</td>\n      <td>2.237324e+06</td>\n    </tr>\n    <tr>\n      <th>716</th>\n      <td>47728.96</td>\n      <td>47748.81</td>\n      <td>47699.54</td>\n      <td>47739.99</td>\n      <td>19.58113</td>\n      <td>9.343993e+05</td>\n      <td>650</td>\n      <td>7.49365</td>\n      <td>3.576146e+05</td>\n    </tr>\n    <tr>\n      <th>717</th>\n      <td>47740.00</td>\n      <td>47799.88</td>\n      <td>47711.43</td>\n      <td>47771.53</td>\n      <td>32.42206</td>\n      <td>1.548339e+06</td>\n      <td>904</td>\n      <td>15.75298</td>\n      <td>7.522625e+05</td>\n    </tr>\n    <tr>\n      <th>718</th>\n      <td>47771.52</td>\n      <td>47771.53</td>\n      <td>47720.25</td>\n      <td>47722.99</td>\n      <td>20.97965</td>\n      <td>1.001710e+06</td>\n      <td>618</td>\n      <td>5.00430</td>\n      <td>2.389313e+05</td>\n    </tr>\n    <tr>\n      <th>719</th>\n      <td>47722.98</td>\n      <td>47741.23</td>\n      <td>47700.00</td>\n      <td>47722.65</td>\n      <td>18.76054</td>\n      <td>8.953514e+05</td>\n      <td>633</td>\n      <td>12.42697</td>\n      <td>5.930911e+05</td>\n    </tr>\n  </tbody>\n</table>\n<p>720 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klines_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [
    {
     "data": {
      "text/plain": "(350, 10, 1)"
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.LSTM(32, batch_input_shape=(batch_size, look_back, 9), stateful=True, return_sequences=True))\n",
    "model.add(tf.keras.layers.Dropout(0.2)) # overfitting을 막기 위해 20% 가량을 drop\n",
    "model.add(tf.keras.layers.LSTM(32, batch_input_shape=(batch_size, look_back, 9), stateful=True))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "# model.add(tf.keras.layers.Dense(64, input_dim= 8, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dense(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "outputs": [],
   "source": [
    "# sgd = tf.keras.optimizers.Adam(learning_rate=0.00000001)\n",
    "# model.compile(loss='mse',optimizer=sgd,metrics=['accuracy'])\n",
    "model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_19 (LSTM)              (5, 3, 32)                5376      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (5, 3, 32)                0         \n",
      "                                                                 \n",
      " lstm_20 (LSTM)              (5, 32)                   8320      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (5, 32)                   0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (5, 1)                    33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,729\n",
      "Trainable params: 13,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0033 - accuracy: 0.0014\n",
      "Epoch 2/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0028 - accuracy: 0.0014\n",
      "Epoch 3/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0027 - accuracy: 0.0014\n",
      "Epoch 4/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0025 - accuracy: 0.0014\n",
      "Epoch 5/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0024 - accuracy: 0.0014\n",
      "Epoch 6/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0025 - accuracy: 0.0014\n",
      "Epoch 7/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0021 - accuracy: 0.0014\n",
      "Epoch 8/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0022 - accuracy: 0.0014\n",
      "Epoch 9/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0021 - accuracy: 0.0014\n",
      "Epoch 10/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0019 - accuracy: 0.0014\n",
      "Epoch 11/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0023 - accuracy: 0.0014\n",
      "Epoch 12/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0021 - accuracy: 0.0014\n",
      "Epoch 13/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0018 - accuracy: 0.0014\n",
      "Epoch 14/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0018 - accuracy: 0.0014\n",
      "Epoch 15/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0019 - accuracy: 0.0014\n",
      "Epoch 16/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0018 - accuracy: 0.0014\n",
      "Epoch 17/50\n",
      "715/715 [==============================] - 2s 2ms/step - loss: 0.0019 - accuracy: 0.0014\n",
      "Epoch 18/50\n",
      "715/715 [==============================] - 2s 3ms/step - loss: 0.0018 - accuracy: 0.0014\n",
      "Epoch 19/50\n",
      "715/715 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.0014\n",
      "Epoch 20/50\n",
      "715/715 [==============================] - 2s 3ms/step - loss: 0.0016 - accuracy: 0.0014\n",
      "Epoch 21/50\n",
      "715/715 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.0014\n",
      "Epoch 22/50\n",
      "715/715 [==============================] - 3s 4ms/step - loss: 0.0019 - accuracy: 0.0014\n",
      "Epoch 23/50\n",
      "715/715 [==============================] - 3s 4ms/step - loss: 0.0017 - accuracy: 0.0014\n",
      "Epoch 24/50\n",
      "715/715 [==============================] - 4s 5ms/step - loss: 0.0021 - accuracy: 0.0014\n",
      "Epoch 25/50\n",
      "715/715 [==============================] - 5s 6ms/step - loss: 0.0016 - accuracy: 0.0014\n",
      "Epoch 26/50\n",
      "715/715 [==============================] - 5s 7ms/step - loss: 0.0018 - accuracy: 0.0014\n",
      "Epoch 27/50\n",
      "715/715 [==============================] - 6s 8ms/step - loss: 0.0016 - accuracy: 0.0014\n",
      "Epoch 28/50\n",
      "715/715 [==============================] - 6s 9ms/step - loss: 0.0018 - accuracy: 0.0014\n",
      "Epoch 29/50\n",
      "545/715 [=====================>........] - ETA: 1s - loss: 0.0018 - accuracy: 0.0018"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train, epochs=50, batch_size=batch_size, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-3.59565020e-04],\n       [ 5.54576516e-03],\n       [ 3.30649018e-02],\n       [ 6.69213235e-02],\n       [ 7.87526667e-02],\n       [ 1.07704818e-01],\n       [ 1.11235231e-01],\n       [ 9.21479464e-02],\n       [ 9.12381411e-02],\n       [ 1.01954579e-01],\n       [ 1.47098303e-01],\n       [ 1.60551280e-01],\n       [ 1.41936481e-01],\n       [ 1.41888350e-01],\n       [ 1.16194129e-01],\n       [ 1.32630259e-01],\n       [ 1.21245414e-01],\n       [ 1.37395322e-01],\n       [ 1.40814096e-01],\n       [ 1.24776453e-01],\n       [ 1.14690214e-01],\n       [ 1.10452771e-01],\n       [ 8.42811465e-02],\n       [ 8.28155279e-02],\n       [ 1.08722210e-01],\n       [ 1.35615587e-01],\n       [ 1.64932638e-01],\n       [ 2.41662458e-01],\n       [ 3.05614531e-01],\n       [ 2.16573492e-01],\n       [ 2.10804507e-01],\n       [ 2.03640923e-01],\n       [ 2.02726036e-01],\n       [ 2.17061043e-01],\n       [ 2.11467281e-01],\n       [ 1.98435307e-01],\n       [ 2.03826681e-01],\n       [ 2.06593126e-01],\n       [ 2.00908273e-01],\n       [ 1.93128556e-01],\n       [ 1.80471271e-01],\n       [ 1.96867436e-01],\n       [ 2.09757119e-01],\n       [ 2.26739630e-01],\n       [ 2.31020689e-01],\n       [ 2.53214836e-01],\n       [ 2.74686962e-01],\n       [ 2.69912690e-01],\n       [ 2.78839856e-01],\n       [ 2.57012039e-01],\n       [ 2.38311887e-01],\n       [ 2.24830478e-01],\n       [ 2.25961000e-01],\n       [ 2.33499348e-01],\n       [ 2.68010974e-01],\n       [ 2.54986346e-01],\n       [ 2.89914489e-01],\n       [ 3.02576005e-01],\n       [ 3.06809723e-01],\n       [ 2.62352288e-01],\n       [ 2.23211050e-01],\n       [ 2.07579508e-01],\n       [ 2.24062085e-01],\n       [ 2.18596607e-01],\n       [ 2.09590107e-01],\n       [ 2.08044305e-01],\n       [ 2.22536936e-01],\n       [ 2.29831293e-01],\n       [ 2.62599468e-01],\n       [ 2.64034361e-01],\n       [ 3.01785886e-01],\n       [ 2.83602536e-01],\n       [ 3.48597765e-01],\n       [ 3.42641860e-01],\n       [ 3.28730404e-01],\n       [ 3.15875649e-01],\n       [ 3.07759553e-01],\n       [ 2.76028454e-01],\n       [ 2.72765994e-01],\n       [ 2.78000593e-01],\n       [ 2.56277829e-01],\n       [ 2.14139074e-01],\n       [ 1.79049194e-01],\n       [ 1.98629528e-01],\n       [ 2.05556542e-01],\n       [ 1.97169572e-01],\n       [ 2.03197777e-01],\n       [ 1.85196280e-01],\n       [ 1.67147398e-01],\n       [ 1.61471158e-01],\n       [ 1.48750067e-01],\n       [ 1.52577400e-01],\n       [ 1.97223693e-01],\n       [ 2.23136723e-01],\n       [ 2.22428367e-01],\n       [ 2.15259671e-01],\n       [ 2.19633922e-01],\n       [ 2.30436265e-01],\n       [ 2.32972413e-01],\n       [ 2.30600417e-01],\n       [ 2.41082177e-01],\n       [ 2.23465875e-01],\n       [ 2.13245839e-01],\n       [ 2.25393236e-01],\n       [ 2.17348710e-01],\n       [ 1.88825309e-01],\n       [ 1.64564818e-01],\n       [ 1.51508331e-01],\n       [ 1.58051133e-01],\n       [ 1.63461536e-01],\n       [ 1.52076870e-01],\n       [ 1.52554393e-01],\n       [ 1.51468098e-01],\n       [ 1.62345976e-01],\n       [ 1.90032125e-01],\n       [ 1.96773261e-01],\n       [ 2.06295803e-01],\n       [ 2.09481210e-01],\n       [ 2.17326939e-01],\n       [ 2.01253533e-01],\n       [ 1.89990997e-01],\n       [ 1.54951721e-01],\n       [ 1.44662082e-01],\n       [ 1.48542672e-01],\n       [ 1.43345147e-01],\n       [ 1.46257311e-01],\n       [ 1.75155252e-01],\n       [ 1.79377824e-01],\n       [ 1.65420115e-01],\n       [ 1.56389326e-01],\n       [ 1.47708744e-01],\n       [ 1.48964286e-01],\n       [ 1.95578545e-01],\n       [ 2.17329666e-01],\n       [ 2.01035947e-01],\n       [ 1.83408946e-01],\n       [ 1.81787103e-01],\n       [ 2.21894175e-01],\n       [ 2.54430354e-01],\n       [ 2.32685819e-01],\n       [ 2.35904694e-01],\n       [ 2.23205939e-01],\n       [ 2.02149838e-01],\n       [ 1.95280254e-01],\n       [ 1.89336926e-01],\n       [ 1.90883130e-01],\n       [ 1.85816348e-01],\n       [ 1.60473198e-01],\n       [ 1.34012103e-01],\n       [ 1.08865708e-01],\n       [ 9.15577412e-02],\n       [ 7.02368021e-02],\n       [ 7.56568909e-02],\n       [ 9.08179581e-02],\n       [ 9.26684439e-02],\n       [ 8.73853266e-02],\n       [ 1.32885784e-01],\n       [ 1.28306568e-01],\n       [ 1.20054394e-01],\n       [ 1.23065770e-01],\n       [ 1.14261329e-01],\n       [ 1.08036608e-01],\n       [ 9.85590816e-02],\n       [ 8.90423656e-02],\n       [ 8.36684108e-02],\n       [ 7.87105262e-02],\n       [ 1.10392869e-01],\n       [ 1.06825590e-01],\n       [ 1.11485243e-01],\n       [ 1.25925183e-01],\n       [ 1.27470195e-01],\n       [ 1.25362247e-01],\n       [ 1.27256900e-01],\n       [ 1.03850067e-01],\n       [ 9.71927643e-02],\n       [ 9.76967216e-02],\n       [ 8.55291486e-02],\n       [ 7.96888173e-02],\n       [ 1.19184971e-01],\n       [ 1.32342249e-01],\n       [ 1.35778755e-01],\n       [ 1.49437577e-01],\n       [ 1.81470901e-01],\n       [ 1.51383042e-01],\n       [ 1.57593310e-01],\n       [ 1.45076543e-01],\n       [ 1.25167608e-01],\n       [ 1.21930569e-01],\n       [ 1.29012555e-01],\n       [ 1.38148993e-01],\n       [ 1.32862240e-01],\n       [ 1.21775836e-01],\n       [ 1.38521194e-01],\n       [ 1.51862383e-01],\n       [ 1.47881687e-01],\n       [ 1.33302867e-01],\n       [ 1.35970056e-01],\n       [ 1.53347760e-01],\n       [ 1.57807797e-01],\n       [ 1.64798290e-01],\n       [ 1.54654175e-01],\n       [ 1.54776901e-01],\n       [ 1.79404080e-01],\n       [ 1.88072026e-01],\n       [ 1.76195562e-01],\n       [ 1.87674373e-01],\n       [ 1.82735145e-01],\n       [ 2.06659570e-01],\n       [ 2.80632198e-01],\n       [ 3.86511326e-01],\n       [ 5.51670611e-01],\n       [ 4.73842084e-01],\n       [ 4.89865869e-01],\n       [ 4.66344684e-01],\n       [ 5.96503556e-01],\n       [ 5.68908215e-01],\n       [ 5.72208941e-01],\n       [ 5.68063617e-01],\n       [ 5.70592403e-01],\n       [ 5.14976859e-01],\n       [ 5.07397294e-01],\n       [ 5.31520605e-01],\n       [ 5.44322610e-01],\n       [ 4.34781253e-01],\n       [ 4.43259567e-01],\n       [ 4.17022258e-01],\n       [ 3.70970964e-01],\n       [ 3.79318833e-01],\n       [ 3.93173903e-01],\n       [ 3.61915439e-01],\n       [ 3.65154445e-01],\n       [ 3.71888131e-01],\n       [ 3.72189611e-01],\n       [ 3.76563907e-01],\n       [ 3.70454043e-01],\n       [ 3.80870461e-01],\n       [ 4.54472303e-01],\n       [ 4.23716277e-01],\n       [ 3.91177922e-01],\n       [ 4.39464211e-01],\n       [ 4.26815093e-01],\n       [ 4.83455092e-01],\n       [ 4.53326374e-01],\n       [ 4.48347926e-01],\n       [ 4.86542732e-01],\n       [ 5.18637419e-01],\n       [ 5.74513912e-01],\n       [ 5.88356256e-01],\n       [ 5.98083377e-01],\n       [ 5.79008222e-01],\n       [ 5.78143001e-01],\n       [ 5.59778273e-01],\n       [ 5.44615865e-01],\n       [ 5.48593640e-01],\n       [ 5.55705190e-01],\n       [ 5.52341819e-01],\n       [ 5.44724941e-01],\n       [ 5.35585821e-01],\n       [ 5.38671911e-01],\n       [ 5.49921453e-01],\n       [ 5.38207591e-01],\n       [ 5.38506389e-01],\n       [ 5.86556077e-01],\n       [ 6.03082001e-01],\n       [ 6.03810072e-01],\n       [ 6.77006066e-01],\n       [ 6.29909992e-01],\n       [ 6.19024813e-01],\n       [ 6.11949980e-01],\n       [ 6.12978756e-01],\n       [ 6.23507500e-01],\n       [ 6.34362936e-01],\n       [ 6.03692293e-01],\n       [ 5.86712241e-01],\n       [ 5.96230149e-01],\n       [ 5.88393688e-01],\n       [ 5.69032967e-01],\n       [ 5.69387376e-01],\n       [ 5.84505856e-01],\n       [ 5.86263239e-01],\n       [ 5.96331716e-01],\n       [ 6.21829391e-01],\n       [ 5.95796466e-01],\n       [ 5.40616035e-01],\n       [ 5.30072629e-01],\n       [ 5.14377058e-01],\n       [ 5.18454850e-01],\n       [ 5.31065464e-01],\n       [ 5.02520680e-01],\n       [ 4.78188813e-01],\n       [ 4.51592028e-01],\n       [ 4.51402247e-01],\n       [ 4.30933714e-01],\n       [ 4.36649859e-01],\n       [ 4.38019246e-01],\n       [ 4.33003694e-01],\n       [ 5.04735887e-01],\n       [ 4.88603354e-01],\n       [ 4.81459856e-01],\n       [ 5.08263290e-01],\n       [ 5.04245281e-01],\n       [ 5.15081882e-01],\n       [ 4.97094363e-01],\n       [ 4.66395944e-01],\n       [ 4.54255074e-01],\n       [ 4.55031514e-01],\n       [ 4.46633279e-01],\n       [ 4.33551848e-01],\n       [ 4.21616554e-01],\n       [ 4.10375834e-01],\n       [ 4.12018925e-01],\n       [ 4.29089576e-01],\n       [ 4.26128119e-01],\n       [ 4.23639327e-01],\n       [ 4.38606858e-01],\n       [ 4.45346504e-01],\n       [ 4.39770907e-01],\n       [ 4.31289077e-01],\n       [ 4.23127949e-01],\n       [ 4.17185992e-01],\n       [ 4.25598741e-01],\n       [ 4.45707858e-01],\n       [ 4.88039255e-01],\n       [ 4.92443234e-01],\n       [ 4.84142721e-01],\n       [ 4.98257786e-01],\n       [ 5.04596293e-01],\n       [ 5.57836473e-01],\n       [ 5.63591421e-01],\n       [ 5.77001572e-01],\n       [ 6.01358473e-01],\n       [ 5.91238976e-01],\n       [ 6.34587407e-01],\n       [ 6.47018850e-01],\n       [ 8.90254319e-01],\n       [ 9.36980963e-01],\n       [ 9.94493783e-01],\n       [ 1.02195120e+00],\n       [ 1.03395915e+00],\n       [ 1.02355194e+00],\n       [ 1.01572061e+00],\n       [ 1.04124856e+00],\n       [ 1.03303051e+00],\n       [ 1.04013014e+00],\n       [ 1.00589454e+00],\n       [ 9.76356983e-01],\n       [ 9.68817174e-01],\n       [ 9.59825575e-01],\n       [ 9.78923440e-01],\n       [ 9.44116116e-01],\n       [ 9.39533114e-01],\n       [ 9.13668931e-01],\n       [ 8.74668598e-01],\n       [ 8.64803195e-01],\n       [ 8.88122678e-01],\n       [ 9.03405666e-01],\n       [ 9.15737331e-01],\n       [ 8.83877873e-01],\n       [ 8.89963865e-01],\n       [ 8.94630671e-01],\n       [ 8.67407560e-01],\n       [ 8.77140224e-01],\n       [ 9.00788784e-01],\n       [ 9.01682854e-01],\n       [ 9.22607243e-01],\n       [ 9.51586246e-01],\n       [ 9.38439608e-01],\n       [ 9.44777012e-01],\n       [ 9.26919281e-01],\n       [ 9.10966992e-01],\n       [ 9.04693305e-01],\n       [ 9.13904488e-01],\n       [ 8.78982425e-01],\n       [ 8.63909006e-01],\n       [ 8.52921367e-01],\n       [ 8.31821084e-01],\n       [ 8.40522766e-01],\n       [ 8.37666750e-01],\n       [ 8.37806106e-01],\n       [ 8.49864602e-01],\n       [ 8.46197307e-01],\n       [ 8.42464983e-01],\n       [ 8.15129042e-01],\n       [ 7.98084438e-01],\n       [ 8.05414200e-01],\n       [ 7.98872590e-01],\n       [ 8.04254413e-01],\n       [ 8.02179158e-01],\n       [ 7.39592612e-01],\n       [ 7.09136248e-01],\n       [ 6.75370216e-01],\n       [ 6.54710412e-01],\n       [ 6.44683778e-01],\n       [ 6.62117898e-01],\n       [ 6.53704047e-01],\n       [ 6.52383447e-01],\n       [ 6.61437035e-01],\n       [ 6.79870367e-01],\n       [ 6.70556426e-01],\n       [ 6.58898354e-01],\n       [ 6.41464531e-01],\n       [ 6.37242973e-01],\n       [ 6.56829119e-01],\n       [ 6.90465331e-01],\n       [ 6.78673387e-01],\n       [ 6.78051114e-01],\n       [ 6.92810237e-01],\n       [ 6.89198315e-01],\n       [ 7.01669455e-01],\n       [ 6.92704916e-01],\n       [ 6.62399530e-01],\n       [ 7.27584600e-01],\n       [ 7.60088086e-01],\n       [ 7.65197396e-01],\n       [ 7.28466451e-01],\n       [ 7.20844209e-01],\n       [ 7.49374747e-01],\n       [ 7.53317237e-01],\n       [ 7.42347479e-01],\n       [ 7.64954925e-01],\n       [ 7.53516912e-01],\n       [ 7.65949368e-01],\n       [ 7.56258190e-01],\n       [ 7.63131082e-01],\n       [ 7.06411123e-01],\n       [ 7.07593918e-01],\n       [ 7.13721514e-01],\n       [ 6.84786081e-01],\n       [ 6.93095922e-01],\n       [ 6.74410343e-01],\n       [ 6.76056266e-01],\n       [ 6.43692791e-01],\n       [ 6.34140253e-01],\n       [ 6.35962069e-01],\n       [ 6.21035099e-01],\n       [ 6.28850758e-01],\n       [ 6.39296889e-01],\n       [ 6.31943583e-01],\n       [ 6.28825545e-01],\n       [ 6.16271019e-01],\n       [ 5.74344158e-01],\n       [ 5.64412534e-01],\n       [ 5.71886480e-01],\n       [ 5.62705040e-01],\n       [ 5.42704701e-01],\n       [ 5.48184752e-01],\n       [ 5.65886855e-01],\n       [ 5.54699361e-01],\n       [ 5.26120842e-01],\n       [ 5.31701505e-01],\n       [ 5.30682325e-01],\n       [ 5.18029273e-01],\n       [ 5.36655188e-01],\n       [ 5.15436292e-01],\n       [ 4.89442647e-01],\n       [ 4.91076976e-01],\n       [ 4.93190438e-01],\n       [ 4.88773823e-01],\n       [ 5.14773607e-01],\n       [ 5.23096442e-01],\n       [ 4.94640261e-01],\n       [ 4.83583748e-01],\n       [ 4.88637447e-01],\n       [ 4.81059998e-01],\n       [ 4.74992156e-01],\n       [ 4.89245027e-01],\n       [ 5.10119915e-01],\n       [ 5.01261055e-01],\n       [ 4.91486847e-01],\n       [ 4.86700207e-01],\n       [ 4.72444057e-01],\n       [ 5.02017140e-01],\n       [ 5.00282109e-01],\n       [ 5.13563395e-01],\n       [ 5.02532125e-01],\n       [ 5.02659380e-01],\n       [ 5.14977872e-01],\n       [ 5.20400763e-01],\n       [ 4.98569250e-01],\n       [ 4.82578009e-01],\n       [ 4.85148519e-01],\n       [ 5.08235455e-01],\n       [ 5.07277727e-01],\n       [ 5.05919695e-01],\n       [ 5.06890416e-01],\n       [ 5.09114623e-01],\n       [ 5.07105052e-01],\n       [ 5.00686467e-01],\n       [ 4.76171672e-01],\n       [ 4.73875672e-01],\n       [ 4.82858360e-01],\n       [ 4.54575807e-01],\n       [ 4.44682002e-01],\n       [ 4.57306683e-01],\n       [ 4.87393916e-01],\n       [ 4.90528375e-01],\n       [ 4.88898784e-01],\n       [ 5.16504228e-01],\n       [ 5.09931803e-01],\n       [ 5.30923843e-01],\n       [ 5.53326964e-01],\n       [ 5.84248662e-01],\n       [ 5.51317692e-01],\n       [ 5.58214128e-01],\n       [ 5.67231178e-01],\n       [ 5.75560033e-01],\n       [ 6.69935584e-01],\n       [ 7.00877011e-01],\n       [ 6.94849074e-01],\n       [ 6.92999721e-01],\n       [ 6.79555476e-01],\n       [ 6.85352147e-01],\n       [ 6.81648731e-01],\n       [ 6.51564121e-01],\n       [ 6.31799579e-01],\n       [ 6.15419328e-01],\n       [ 6.02790534e-01],\n       [ 5.95479250e-01],\n       [ 5.73593974e-01],\n       [ 5.70538640e-01],\n       [ 5.59383512e-01],\n       [ 5.78656077e-01],\n       [ 6.17818296e-01],\n       [ 6.06614053e-01],\n       [ 5.79832911e-01],\n       [ 5.61436296e-01],\n       [ 5.47347188e-01],\n       [ 5.30596018e-01],\n       [ 5.50754070e-01],\n       [ 5.38760722e-01],\n       [ 5.42885065e-01],\n       [ 5.53634524e-01],\n       [ 5.76004446e-01],\n       [ 5.70109010e-01],\n       [ 5.90512812e-01],\n       [ 5.63339174e-01],\n       [ 5.77423871e-01],\n       [ 5.68500280e-01],\n       [ 5.57505310e-01],\n       [ 5.54064512e-01],\n       [ 5.60873270e-01],\n       [ 5.62493920e-01],\n       [ 5.76264024e-01],\n       [ 5.65099895e-01],\n       [ 5.56889892e-01],\n       [ 5.62066376e-01],\n       [ 5.62429786e-01],\n       [ 5.79262376e-01],\n       [ 5.97904325e-01],\n       [ 6.00275874e-01],\n       [ 7.11153030e-01],\n       [ 6.66694939e-01],\n       [ 6.87515616e-01],\n       [ 6.69312239e-01],\n       [ 6.51613832e-01],\n       [ 6.22849286e-01],\n       [ 5.96698880e-01],\n       [ 6.01586938e-01],\n       [ 5.97257853e-01],\n       [ 6.02110744e-01],\n       [ 5.83174825e-01],\n       [ 5.69989324e-01],\n       [ 5.54641843e-01],\n       [ 5.24362624e-01],\n       [ 5.24935126e-01],\n       [ 5.24555147e-01],\n       [ 5.23627460e-01],\n       [ 5.18661737e-01],\n       [ 5.88741899e-01],\n       [ 5.96269369e-01],\n       [ 5.79010367e-01],\n       [ 6.32856607e-01],\n       [ 6.38403296e-01],\n       [ 6.29209220e-01],\n       [ 6.14066124e-01],\n       [ 6.07576072e-01],\n       [ 6.07396960e-01],\n       [ 6.10227585e-01],\n       [ 5.72712481e-01],\n       [ 6.05885446e-01],\n       [ 6.13983989e-01],\n       [ 6.18749738e-01],\n       [ 6.01317108e-01],\n       [ 5.66071272e-01],\n       [ 4.99464512e-01],\n       [ 4.70635444e-01],\n       [ 4.59236711e-01],\n       [ 4.50388312e-01],\n       [ 4.59206820e-01],\n       [ 4.52136427e-01],\n       [ 4.50744927e-01],\n       [ 4.48255062e-01],\n       [ 4.79571104e-01],\n       [ 4.86012280e-01],\n       [ 4.62342978e-01],\n       [ 4.82287198e-01],\n       [ 5.04692614e-01],\n       [ 5.00463843e-01],\n       [ 5.16896963e-01],\n       [ 5.28257072e-01],\n       [ 5.17824531e-01],\n       [ 5.21103621e-01],\n       [ 5.16189396e-01],\n       [ 4.96453196e-01],\n       [ 4.78270978e-01],\n       [ 4.91512388e-01],\n       [ 4.85122353e-01],\n       [ 4.84042376e-01],\n       [ 4.47585315e-01],\n       [ 4.30051506e-01],\n       [ 4.56546694e-01],\n       [ 4.41554219e-01],\n       [ 4.42529470e-01],\n       [ 4.44601268e-01],\n       [ 4.62363571e-01],\n       [ 4.56112534e-01],\n       [ 4.52991992e-01],\n       [ 4.45481688e-01],\n       [ 4.51746315e-01],\n       [ 4.48691964e-01],\n       [ 4.91404235e-01],\n       [ 4.98874098e-01],\n       [ 5.39702237e-01],\n       [ 5.70207894e-01],\n       [ 5.50135434e-01],\n       [ 5.50219715e-01],\n       [ 5.54197192e-01],\n       [ 5.62230527e-01],\n       [ 5.53964257e-01],\n       [ 5.50629437e-01],\n       [ 5.52795112e-01],\n       [ 5.87650657e-01],\n       [ 6.05170667e-01],\n       [ 6.27111554e-01],\n       [ 6.43608809e-01],\n       [ 6.47943497e-01],\n       [ 6.37057066e-01],\n       [ 6.24894917e-01],\n       [ 6.18707955e-01],\n       [ 6.12683892e-01],\n       [ 6.12239659e-01],\n       [ 6.20874286e-01],\n       [ 6.41927481e-01],\n       [ 6.41263664e-01],\n       [ 6.33313298e-01],\n       [ 6.29340231e-01],\n       [ 6.40597463e-01],\n       [ 6.29752278e-01],\n       [ 5.75278282e-01],\n       [ 5.55056810e-01],\n       [ 6.07842088e-01],\n       [ 5.98453224e-01],\n       [ 5.92658043e-01],\n       [ 6.07791185e-01],\n       [ 5.95760703e-01],\n       [ 5.96914530e-01],\n       [ 5.99443913e-01],\n       [ 5.36666095e-01],\n       [ 5.13764381e-01],\n       [ 5.14316738e-01],\n       [ 5.09598017e-01],\n       [ 5.09292603e-01],\n       [ 5.35656869e-01],\n       [ 5.60897470e-01],\n       [ 5.62945485e-01],\n       [ 5.46849668e-01],\n       [ 5.63039482e-01],\n       [ 5.41479349e-01],\n       [ 5.41596055e-01],\n       [ 5.21973372e-01],\n       [ 5.09675920e-01],\n       [ 5.14833093e-01],\n       [ 5.32974660e-01],\n       [ 5.60623467e-01],\n       [ 5.75527728e-01],\n       [ 5.85618019e-01],\n       [ 5.74158192e-01],\n       [ 5.46523154e-01],\n       [ 5.29236555e-01],\n       [ 5.34510374e-01],\n       [ 5.93483627e-01],\n       [ 6.30339503e-01],\n       [ 6.25100851e-01],\n       [ 6.02671504e-01],\n       [ 5.89777410e-01],\n       [ 5.99198878e-01],\n       [ 5.71990073e-01],\n       [ 5.63387811e-01],\n       [ 5.87603867e-01],\n       [ 6.02362633e-01],\n       [ 6.33489370e-01],\n       [ 6.82729840e-01],\n       [ 7.20341086e-01],\n       [ 7.19515979e-01],\n       [ 7.21691847e-01],\n       [ 7.13931084e-01],\n       [ 6.93862498e-01],\n       [ 6.90393865e-01],\n       [ 6.93666875e-01],\n       [ 7.02982366e-01],\n       [ 6.75339758e-01],\n       [ 6.92320585e-01],\n       [ 6.93101227e-01],\n       [ 7.20189571e-01],\n       [ 7.19246030e-01],\n       [ 7.29320228e-01],\n       [ 7.19026446e-01],\n       [ 7.17130542e-01],\n       [ 7.10465848e-01],\n       [ 7.17331529e-01],\n       [ 8.67029428e-01],\n       [ 8.64869535e-01],\n       [ 9.05478001e-01],\n       [ 9.22750354e-01],\n       [ 8.97154808e-01]], dtype=float32)"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict = model.predict(x_train, batch_size)\n",
    "y_predict"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "non-broadcastable output operand with shape (715,1) doesn't match the broadcast shape (715,9)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [254]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0m real_predictions \u001B[38;5;241m=\u001B[39m \u001B[43mscaler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minverse_transform\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_predict\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 0~1의 값으로 정규화된 값을 원래의 크기로 되돌린다.  \u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# print(\"predicted next 5 min trade count\", real_predictions[-1])  # 예측한 건수를 출력한다.\u001B[39;00m\n\u001B[1;32m      4\u001B[0m real_predictions\n",
      "File \u001B[0;32m/opt/anaconda3/envs/dev_py38/lib/python3.8/site-packages/sklearn/preprocessing/_data.py:529\u001B[0m, in \u001B[0;36mMinMaxScaler.inverse_transform\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    523\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    525\u001B[0m X \u001B[38;5;241m=\u001B[39m check_array(\n\u001B[1;32m    526\u001B[0m     X, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcopy, dtype\u001B[38;5;241m=\u001B[39mFLOAT_DTYPES, force_all_finite\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    527\u001B[0m )\n\u001B[0;32m--> 529\u001B[0m X \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_\n\u001B[1;32m    530\u001B[0m X \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale_\n\u001B[1;32m    531\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m X\n",
      "\u001B[0;31mValueError\u001B[0m: non-broadcastable output operand with shape (715,1) doesn't match the broadcast shape (715,9)"
     ]
    }
   ],
   "source": [
    "real_predictions = scaler.inverse_transform(y_predict)  # 0~1의 값으로 정규화된 값을 원래의 크기로 되돌린다.\n",
    "# print(\"predicted next 5 min trade count\", real_predictions[-1])  # 예측한 건수를 출력한다.\n",
    "\n",
    "real_predictions\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[4.72407300e+04, 4.72407600e+04, 4.71803800e+04, 5.37555000e+00,\n        2.53763106e+05, 3.32000000e+02, 1.22749000e+00, 5.79562821e+04],\n       [4.71959900e+04, 4.72365500e+04, 4.71927200e+04, 1.22461800e+01,\n        5.78216273e+05, 3.84000000e+02, 5.33622000e+00, 2.51929215e+05],\n       [4.72072000e+04, 4.72749800e+04, 4.71965100e+04, 1.51492000e+01,\n        7.15603727e+05, 5.06000000e+02, 8.98866000e+00, 4.24579953e+05],\n       [4.72595400e+04, 4.72734000e+04, 4.72500000e+04, 7.71686000e+00,\n        3.64711302e+05, 3.60000000e+02, 3.39986000e+00, 1.60677519e+05],\n       [4.72699900e+04, 4.73144700e+04, 4.72500000e+04, 1.22686600e+01,\n        5.80187615e+05, 5.68000000e+02, 6.55229000e+00, 3.09865206e+05],\n       [4.72663800e+04, 4.72999900e+04, 4.72500000e+04, 8.46017000e+00,\n        3.99921145e+05, 3.73000000e+02, 2.36634000e+00, 1.11844237e+05],\n       [4.72500100e+04, 4.72500200e+04, 4.71580100e+04, 1.89022100e+01,\n        8.92377703e+05, 5.66000000e+02, 7.80930000e+00, 3.68697408e+05],\n       [4.71819800e+04, 4.71979300e+04, 4.71353000e+04, 1.43532600e+01,\n        6.76893423e+05, 5.34000000e+02, 9.08453000e+00, 4.28449488e+05],\n       [4.71833300e+04, 4.72146000e+04, 4.71799900e+04, 5.54509000e+00,\n        2.61750339e+05, 2.90000000e+02, 2.30579000e+00, 1.08830248e+05],\n       [4.71800100e+04, 4.72145900e+04, 4.71800000e+04, 7.37548000e+00,\n        3.48157796e+05, 3.39000000e+02, 3.95712000e+00, 1.86789588e+05]])"
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test[14]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.models.load_model(\"resource/model/regression_20220415.h5\")\n",
    "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
    "model.save(\"regression_20220415.h5\")\n",
    "\n",
    "# It can be used to reconstruct the model identically.\n",
    "# reconstructed_model = keras.models.load_model(\"my_h5_model.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def create_dataset(signal_data, look_back=1):\n",
    "    x_arr, y_arr = [], []\n",
    "    for i in range(len(signal_data) - look_back):\n",
    "        x_arr.append(signal_data[i:(i + look_back), 0])\n",
    "        y_arr.append(signal_data[i + look_back, 0])\n",
    "\n",
    "    x_arr = np.array(x_arr)\n",
    "    x_arr = np.reshape(x_arr, (x_arr.shape[0], x_arr.shape[1], 1))\n",
    "    return x_arr, np.array(y_arr)\n",
    "\n",
    "klines_dataset = pd.read_csv('resource/dataset/binance/klines-BTCUSDT-1m_20220101090000_20220101205900.csv').to_numpy()\n",
    "\n",
    "# 훈련\n",
    "train = klines_dataset[0:int(len(klines_dataset) * 0.5)]\n",
    "# 검증\n",
    "val = klines_dataset[int(len(klines_dataset) * 0.5):int(len(klines_dataset) * 0.75)]\n",
    "# 시험\n",
    "test = klines_dataset[int(len(klines_dataset) * 0.75):-1]\n",
    "\n",
    "x_train, y_train = create_dataset(train, look_back)\n",
    "x_val, y_val = create_dataset(val, look_back)\n",
    "x_test, y_test = create_dataset(test, look_back)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}